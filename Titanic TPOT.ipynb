{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_labelize_titanic(filename, encoders=None):\n",
    "    \"\"\"Read csv and perform basic labeling encoding\"\"\"\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    if not encoders:\n",
    "        encoders = {'Sex': LabelEncoder(), \n",
    "                    'Cabin': LabelEncoder(), \n",
    "                    'Embarked': LabelEncoder()}\n",
    "        for column, encoder in encoders.items():\n",
    "            encoder.fit(list(df[column].astype(str)) + ['UnknownLabel'])\n",
    "            df[column] = encoder.transform(df[column].astype(str))\n",
    "    else:\n",
    "        for column, encoder in encoders.items():\n",
    "            df.loc[~df[column].isin(encoder.classes_), column] = 'UnknownLabel'\n",
    "            df[column] = encoder.transform(df[column].astype(str))\n",
    "        \n",
    "    df = df.fillna(-999)\n",
    "    passenger_ids = df['PassengerId']\n",
    "    df = df.drop(['PassengerId', 'Name', 'Ticket'], axis=1)\n",
    "    return df, encoders, passenger_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, encoders, _ = load_and_labelize_titanic('titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  33%|███▎      | 100/300 [00:57<01:29,  2.24pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8305358170670338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  50%|█████     | 150/300 [01:34<03:28,  1.39s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.8316971459191776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  67%|██████▋   | 200/300 [02:24<01:57,  1.18s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.8316971459191776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  83%|████████▎ | 250/300 [03:52<00:55,  1.12s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.8316971459191776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 0.8317038485531001\n",
      "\n",
      "Best pipeline: RandomForestClassifier(input_matrix, bootstrap=True, criterion=entropy, max_features=0.9, min_samples_leaf=2, min_samples_split=5, n_estimators=100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.naive_bayes.MultinomialNB': {'fit_prior': [True, False], 'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}, 'sklearn.feature_selection.VarianceThreshold': {'threshold': array([ 0.05,  0.1 ,  0.15,  0.2 ,  0.25,  0.3 ,  0.35,  0.4 ,  0.45,\n",
       "        0.5 ,  0.55,  0.6 ,  0.65,  0.7 , ...tpot.builtins.OneHotEncoder': {'sparse': [False], 'minimum_fraction': [0.05, 0.1, 0.15, 0.2, 0.25]}},\n",
       "        crossover_rate=0.1, cv=5, disable_update_check=False,\n",
       "        early_stop=None, generations=5, max_eval_time_mins=5,\n",
       "        max_time_mins=None, mutation_rate=0.9, n_jobs=1, offspring_size=50,\n",
       "        periodic_checkpoint_folder=None, population_size=50,\n",
       "        random_state=None, scoring=None, subsample=1.0, verbosity=2,\n",
       "        warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, \n",
    "                     n_jobs=1, scoring='accuracy')\n",
    "tpot.fit(train.drop('Survived', axis=1).values, train['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, _, passenger_ids = load_and_labelize_titanic('titanic/test.csv', encoders)\n",
    "results = tpot.predict(test)\n",
    "results_df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': results})\n",
    "results_df.to_csv('titanic/predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
